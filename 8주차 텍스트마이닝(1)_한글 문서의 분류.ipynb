{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 한글 문서의 분류\n",
    "\n",
    "###  data file 내용\n",
    "'신과함께', '코코', '라라랜드', '인피니티 워', '곤지암' 다섯개의 영화에 대해 총 1827개의 리뷰를 수집 csv 파일 안에 리뷰내용, 평점, 영화이름 의 순으로 저장되어 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "text = []\n",
    "y = []\n",
    "with open('movie_data.csv', encoding='utf-8') as csvfile:\n",
    "    csvreader = csv.reader(csvfile)\n",
    "    for row in csvreader:\n",
    "        if row: \n",
    "            text.append(row[0]) \n",
    "            y.append(row[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of samples: 1827\n",
      "Movie titles of reivews: {'인피니티 워', '라라랜드', '곤지암', '코코', '신과함께'}\n"
     ]
    }
   ],
   "source": [
    "print('Num of samples: {}'.format(len(text)))\n",
    "print('Movie titles of reivews: {}'.format(set(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(text, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1370"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "twitter_tag = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['혹시', '나', '하고', '봤는데', '역시', '나다', ';;', '편집', '과', '사운드', '로', '주는', '작은', '공포', '영화', \"'\", '푸시', \"'\", '에서', '인상', '깊게', '봤던걸', '여기', '서', '또', '보네', ';;']\n"
     ]
    }
   ],
   "source": [
    "print(twitter_tag.morphs(X_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['혹시', '역시', '편집', '사운드', '공포', '영화', '푸시', '인상', '여기', '또']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_tag.nouns(X_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twit_tokenizer(text):\n",
    "    return twitter_tag.nouns(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score 0.8153284671532847\n",
      "Test score 0.6717724288840262\n",
      "(1370, 1156)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ebiz\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\ebiz\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "tfidf = TfidfVectorizer(tokenizer=twit_tokenizer, min_df=2)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train) \n",
    "X_test_tfidf = tfidf.transform(X_test) \n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_tfidf, y_train) \n",
    "print('Train score', clf.score(X_train_tfidf, y_train)) \n",
    "print('Test score', clf.score(X_test_tfidf, y_test))\n",
    "print(X_train_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['졸잼 최고',\n",
       " '내용, 음악 , 연기력  무엇하나 빠지는것이 없네요 특히 음악은 계속 찾아 듣게되요^^',\n",
       " '아맥2D로 느즈막히 관람.... 히어로가 많이나오지만, 이걸 꽤나 잘 버무려놓음. 뻔한스토리의 틀을 벗어나려 노력한점은 높은점수를 줄만함.... 블럭버스터액션, 영상미는 말이필요없음...... 후속편 기대됨!',\n",
       " '후반부터 쫄렸다.',\n",
       " '진짜. 솔직히 한국 공포영화중에 이렇게 소재별로인건 정말 오랜만인듯; 지들끼리 소리지르고 정신없이 우왕자왕 심지어 무섭지도않어 효과음만크고 진짜최악임ㅉㅉ',\n",
       " '소문난 잔치에 먹을거 없음..ㅜㅜ',\n",
       " 'good!',\n",
       " '아 점수를 줄 수가 없네  화면은 왜그리도 흔들어 데는지........ 재미도 없고 가볍기만하고 .... 최악의 재미없는 배멀미 영화',\n",
       " '영화 보면서 펑펑물었네요~ 부모님 사랑에 대해 다시한번 생각하게 했던 영화네요^ ^',\n",
       " '슬픈 스토리지만 삶을 돌아보게 하는 영화다. 죄를 지은자는 그 벌을 고스란히 받으리라. 사회 각종범죄자들 뉘우치길 바란다.']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['인피니티 워', '라라랜드', '인피니티 워', '곤지암', '곤지암', '인피니티 워', '인피니티 워',\n",
       "       '신과함께', '코코', '신과함께'], dtype='<U6')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test_tfidf[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['인피니티 워', '라라랜드', '인피니티 워', '곤지암', '곤지암', '인피니티 워', '인피니티 워', '곤지암', '신과함께', '신과함께']\n"
     ]
    }
   ],
   "source": [
    "print(y_test[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 성능을 개선하기 위한 노력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['혹시', '나', '하고', '봤는데', '역시', '나다', ';;', '편집', '과', '사운드', '로', '주는', '작은', '공포', '영화', \"'\", '푸시', \"'\", '에서', '인상', '깊게', '봤던걸', '여기', '서', '또', '보네', ';;']\n"
     ]
    }
   ],
   "source": [
    "print(twitter_tag.morphs(X_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score 0.8802919708029197\n",
      "Test score 0.6433260393873085\n",
      "(1370, 2260)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=twitter_tag.morphs, min_df=2) \n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "print('Train score', clf.score(X_train_tfidf, y_train))\n",
    "print('Test score', clf.score(X_test_tfidf, y_test))\n",
    "print(X_train_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('혹시', 'Noun'), ('나', 'Josa'), ('하다', 'Verb'), ('보다', 'Verb'), ('역시', 'Noun'), ('나다', 'Verb'), (';;', 'Punctuation'), ('편집', 'Noun'), ('과', 'Josa'), ('사운드', 'Noun'), ('로', 'Josa'), ('주다', 'Verb'), ('작다', 'Adjective'), ('공포', 'Noun'), ('영화', 'Noun'), (\"'\", 'Punctuation'), ('푸시', 'Noun'), (\"'\", 'Punctuation'), ('에서', 'Josa'), ('인상', 'Noun'), ('깊다', 'Adjective'), ('보다', 'Verb'), ('여기', 'Noun'), ('서', 'Josa'), ('또', 'Noun'), ('보다', 'Verb'), (';;', 'Punctuation')]\n"
     ]
    }
   ],
   "source": [
    "print(twitter_tag.pos(X_train[1], norm=True, stem=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twit_tokenizer2(text): \n",
    "    target_tags = ['Noun', 'Verb', 'Adjective']\n",
    "    result = []\n",
    "    for word, tag in twitter_tag.pos(text, norm=True, stem=True):\n",
    "        if tag in target_tags:\n",
    "            result.append(word)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['혹시', '하다', '보다', '역시', '나다', '편집', '사운드', '주다', '작다', '공포', '영화', '푸시', '인상', '깊다', '보다', '여기', '또', '보다']\n"
     ]
    }
   ],
   "source": [
    "print(twit_tokenizer2(X_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score 0.8540145985401459\n",
      "Test score 0.6892778993435449\n",
      "(1370, 1584)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=twit_tokenizer2, min_df=2) \n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "print('Train score', clf.score(X_train_tfidf, y_train))\n",
    "print('Test score', clf.score(X_test_tfidf, y_test))\n",
    "print(X_train_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twit_tokenizer3(text):\n",
    "    result = []\n",
    "    for word, tag in twitter_tag.pos(text, norm=True, stem=True):\n",
    "        result.append('/'.join([word, tag])) \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score 0.8751824817518248\n",
      "Test score 0.6695842450765864\n",
      "(1370, 2023)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=twit_tokenizer3, min_df=2)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "print('Train score', clf.score(X_train_tfidf, y_train))\n",
    "print('Test score', clf.score(X_test_tfidf, y_test))\n",
    "print(X_train_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.944\n",
      "Test set score: 0.676\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "ridge_clf = RidgeClassifier(alpha = 1)\n",
    "ridge_clf.fit(X_train_tfidf, y_train)\n",
    "print('Train set score: {:.3f}'.format(ridge_clf.score(X_train_tfidf, y_train)))\n",
    "print('Test set score: {:.3f}'.format(ridge_clf.score(X_test_tfidf, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.718\n",
      "Test set score: 0.643\n",
      "Used features count: 240 out of 2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ebiz\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "lasso_clf = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "lasso_clf.fit(X_train_tfidf, y_train)\n",
    "print('Train set score: {:.3f}'.format(lasso_clf.score(X_train_tfidf, y_train)))\n",
    "print('Test set score: {:.3f}'.format(lasso_clf.score(X_test_tfidf, y_test)))\n",
    "print('Used features count: {}'.format(np.sum(lasso_clf.coef_ != 0)), 'out of', X_train_tfidf.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01102934 0.01405529 0.01144551 0.0110093  0.00918016 0.00876149\n",
      " 0.00836851 0.00795922 0.00777003 0.00737423 0.00707199 0.00665546\n",
      " 0.00659729 0.00616382 0.00588976 0.00563969 0.00546929 0.00543044\n",
      " 0.00524396 0.00523751 0.0051354  0.00507564 0.00494917 0.00478661\n",
      " 0.00466253 0.0046021  0.00455272 0.00452943 0.00432636 0.0043043\n",
      " 0.00425346 0.00416261 0.00410043 0.00401296 0.00399825 0.00396182\n",
      " 0.00392779 0.00385998 0.00373325 0.00369469 0.00365484 0.00363113\n",
      " 0.00357832 0.00354544 0.00349848 0.00346928 0.00337552 0.00334918\n",
      " 0.00332458 0.00330956 0.00323571 0.00321667 0.00315217 0.00314053\n",
      " 0.00309441 0.00307477 0.0030649  0.00301359 0.00300256 0.00296081\n",
      " 0.00293836 0.00291433 0.00288938 0.00288701 0.00286437 0.00281526\n",
      " 0.00280011 0.00276482 0.00274032 0.00271676 0.00269105 0.00266254\n",
      " 0.00264105 0.00262961 0.00260318 0.00258836 0.00257263 0.0025549\n",
      " 0.00253862 0.00252722 0.00251281 0.00248844 0.00248194 0.00245121\n",
      " 0.00244755 0.00241116 0.00239864 0.0023803  0.00236743 0.00235925\n",
      " 0.00232777 0.00231998 0.00228583 0.00225879 0.00224278 0.00222963\n",
      " 0.00222807 0.00219394 0.00218403 0.00217777 0.00216885 0.00213963\n",
      " 0.00213221 0.00211726 0.0021082  0.00208491 0.00207873 0.00206984\n",
      " 0.0020442  0.00203715 0.00203109 0.00202247 0.00200684 0.00199728\n",
      " 0.00198139 0.00197578 0.00196858 0.0019567  0.00195046 0.00193928\n",
      " 0.00192188 0.00191527 0.00190398 0.00190288 0.00189315 0.00188382\n",
      " 0.00186635 0.00185401 0.00184764 0.00184161 0.0018402  0.00182065\n",
      " 0.001813   0.00179631 0.00179194 0.00178155 0.00177619 0.00177247\n",
      " 0.00176391 0.00174575 0.00174084 0.00173493 0.00172713 0.00172038\n",
      " 0.00171324 0.00169736 0.00169107 0.00168815 0.00167718 0.00166958\n",
      " 0.0016606  0.00165005 0.00164831 0.00163445 0.00162676 0.00162542\n",
      " 0.00161713 0.00161272 0.00159771 0.00159238 0.00159037 0.00158957\n",
      " 0.00156833 0.00156387 0.00155943 0.00155314 0.00154517 0.00154178\n",
      " 0.00153878 0.00153156 0.00152027 0.00151681 0.00150908 0.00150907\n",
      " 0.00150429 0.00148962 0.00148561 0.00147865 0.00147801 0.00146682\n",
      " 0.00146001 0.00145723 0.00144468 0.00143961 0.00143002 0.00142921\n",
      " 0.0014208  0.00141638 0.00141579 0.00140818 0.0014034  0.00139324\n",
      " 0.00139056 0.00138567 0.00137493 0.00137155 0.00136727 0.00135985\n",
      " 0.00135444 0.00134977 0.00134562 0.00133558 0.00133122 0.00132535\n",
      " 0.00132194 0.00131758 0.00131066 0.00130911 0.00130505 0.00129728\n",
      " 0.00129571 0.00128405 0.00127616 0.00127324 0.00126559 0.00125941\n",
      " 0.00125722 0.00125095 0.00124375 0.00124088 0.00123686 0.00123166\n",
      " 0.00122136 0.00121416 0.00120729 0.00119822 0.00119425 0.0011902\n",
      " 0.00118219 0.00117517 0.00117452 0.0011669  0.00115835 0.00114922\n",
      " 0.00114639 0.00113962 0.00113862 0.00113157 0.00112449]\n",
      "0.6274704549280452\n",
      "[7.18722998 4.37716265 3.87707769 3.80401495 3.46987465 3.38992696\n",
      " 3.31319188 3.23081401 3.19295868 3.11176267 3.0479269  2.97464527\n",
      " 2.94181282 2.84376785 2.7792728  2.72052017 2.67818072 2.66871722\n",
      " 2.62671166 2.6211839  2.59772293 2.58190277 2.54773577 2.50549056\n",
      " 2.47514125 2.46249764 2.44458218 2.44081919 2.38195771 2.37595715\n",
      " 2.36213857 2.33646299 2.31897222 2.29462272 2.28988032 2.27951064\n",
      " 2.2696032  2.25224959 2.21275983 2.20157946 2.18941753 2.18229454\n",
      " 2.16700863 2.15629757 2.14384191 2.13417342 2.10461423 2.09580568\n",
      " 2.08809633 2.08457671 2.06118326 2.05524985 2.03983521 2.02947381\n",
      " 2.0156339  2.00808902 2.00484508 1.98892489 1.9848698  1.97080544\n",
      " 1.96433732 1.95685115 1.94851579 1.94618356 1.93878407 1.92354149\n",
      " 1.91631125 1.90417728 1.8957369  1.88786307 1.8786183  1.86911358\n",
      " 1.86110158 1.85717919 1.84914318 1.84466386 1.83680751 1.83047136\n",
      " 1.8257132  1.82052779 1.81602147 1.80661829 1.80431053 1.79331989\n",
      " 1.79183982 1.77843174 1.77363887 1.76688172 1.76225481 1.75901716\n",
      " 1.7472136  1.74547341 1.73138953 1.72112568 1.71500666 1.71000327\n",
      " 1.70948057 1.69627556 1.69249592 1.69011496 1.68727252 1.67602962\n",
      " 1.67226219 1.66647038 1.66276613 1.65396201 1.65116958 1.64756305\n",
      " 1.63885047 1.6351727  1.63216299 1.62859852 1.62272231 1.6199386\n",
      " 1.61197651 1.60973638 1.60686067 1.6019874  1.59937235 1.59485625\n",
      " 1.58767203 1.58485923 1.58104529 1.57976164 1.57568875 1.57192692\n",
      " 1.56637507 1.55945183 1.55681473 1.55449401 1.55349754 1.54521608\n",
      " 1.54228311 1.53494218 1.53323466 1.52873209 1.52685008 1.52467317\n",
      " 1.52095301 1.51360868 1.51136655 1.50844406 1.50501843 1.50295063\n",
      " 1.4990343  1.49203042 1.48921439 1.48844592 1.48323386 1.47971939\n",
      " 1.47588973 1.47125412 1.47030967 1.46441287 1.46089164 1.4600098\n",
      " 1.45645421 1.45430045 1.44757356 1.4451948  1.44418574 1.44381833\n",
      " 1.43474477 1.43241517 1.43075667 1.42734688 1.4239681  1.42213184\n",
      " 1.42056782 1.41722678 1.4129636  1.41085354 1.40692287 1.40682537\n",
      " 1.40490821 1.39769447 1.39580527 1.39275219 1.3922484  1.38695654\n",
      " 1.38382998 1.38275183 1.37645068 1.37404564 1.36964869 1.36905779\n",
      " 1.36514341 1.36291003 1.36262579 1.35901456 1.35666126 1.35220907\n",
      " 1.35071654 1.34873489 1.34301621 1.34134439 1.33943739 1.33542613\n",
      " 1.33276808 1.33056349 1.3284238  1.32349714 1.32147413 1.31838175\n",
      " 1.31677435 1.31457724 1.31126584 1.31041624 1.30838878 1.30434815\n",
      " 1.30356031 1.29770436 1.29424264 1.29220091 1.28853219 1.28520775\n",
      " 1.2841347  1.28089417 1.27725376 1.27569374 1.27362989 1.27093976\n",
      " 1.26565419 1.26203966 1.25829658 1.25355624 1.25168127 1.24946418\n",
      " 1.24542796 1.24144044 1.24113263 1.23706028 1.2325742  1.22773662\n",
      " 1.22629484 1.22251701 1.22209418 1.21818685 1.21495199]\n",
      "(239, 2023)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=239, n_iter=7, random_state=42) \n",
    "svd.fit(X_train_tfidf)  \n",
    "print(svd.explained_variance_ratio_) \n",
    "print(svd.explained_variance_ratio_.sum()) \n",
    "print(svd.singular_values_) \n",
    "print(svd.components_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.763\n",
      "Test set score: 0.654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ebiz\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\ebiz\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train_svd = svd.transform(X_train_tfidf)\n",
    "X_test_svd = svd.transform(X_test_tfidf)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "SVD_clf = LogisticRegression()\n",
    "SVD_clf.fit(X_train_svd, y_train)\n",
    "print('Train set score: {:.3f}'.format(SVD_clf.score(X_train_svd, y_train)))\n",
    "print('Test set score: {:.3f}'.format(SVD_clf.score(X_test_svd, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set dimension: (1370, 1584)\n",
      "Test set dimension: (457, 1584)\n",
      "Train set score: 0.801\n",
      "Test set score: 0.685\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(tokenizer=twit_tokenizer2, min_df=2).fit(X_train)\n",
    "X_train_cv = cv.transform(X_train)\n",
    "print('Train set dimension:', X_train_cv.shape)\n",
    "X_test_cv = cv.transform(X_test)\n",
    "print('Test set dimension:', X_test_cv.shape)\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "NB_clf = MultinomialNB()\n",
    "NB_clf.fit(X_train_cv, y_train)\n",
    "print('Train set score: {:.3f}'.format(NB_clf.score(X_train_cv, y_train)))\n",
    "print('Test set score: {:.3f}'.format(NB_clf.score(X_test_cv, y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
